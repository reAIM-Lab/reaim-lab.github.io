---
layout: article
title: Research
key: research
---


<style>
  .publication {
    display: flex;
    margin-bottom: 30px;
  }

  .publication img {
    width: 500px;
    margin-right: 20px;
    border-radius: 10px;
  }

  .publication .text {
    flex: 1;
  }

  @media (max-width: 800px) {
    .publication {
      flex-direction: column;
    }

    .publication img {
      margin-right: 0;
      margin-bottom: 10px;
      border-radius: 10px;
    }
  }
</style>

<h3>New AI models for reliable inference and predictions in high-dimensional multimodal health and biomedicine data</h3>

We are developing AI models for clinical and biomedical data for meaningful downstream tasks. Brute forcing existing inductive biases and architectures can lead to unreliable scientific inference and predictions. Therefore, the lab focuses on developing data representations, learning tasks, and model architectures that will be robust to large distributional shifts, and evaluated with robust frameworks to test inferential capabilities.<br>

<div class="publication">
  <!--img src="assets/images/joshi_aaai_2024.png" alt="Publication Image 1" /-->
  <div class="text">
    <a href="https://arxiv.org/pdf/2505.16953?" target="_blank"><strong>ICYM2I: The illusion of multimodal informativeness under missingness</strong></a><br>
    <strong><span style="color: #003087;">Young Sang Choi*, Vincent Jeanselme*, Pierre Elias, Shalmali Joshi.</span></strong><br>
    <!--i>Neural Information Processing Systems (NeurIPS) 2024</i><br-->
  </div>
</div>


<h3>Adaptive AI systems and representations to improve generalizability and robustness</h3>

Enabling systems that generalize to out-of-distribution data requires adaptive AI approaches where models can improve from their mistakes. We leverage probabilistic modeling, reinforcement learning, and deep learning to overcome imperfections of observational health and medicine data and develop adaptive multimodal AI systems.<br>

<div class="publication">
  <!--img src="assets/images/joshi_aaai_2024.png" alt="Publication Image 1" /-->
  <div class="text">
    <a href="https://openreview.net/pdf?id=uuQQwrjMzb" target="_blank"><strong>Adaptive Labeling for Efficient Out-of-distribution Model Evaluation</strong></a><br>
    Daksh Mittal, Yuanzhe Ma, <strong><span style="color: #003087;">Shalmali Joshi</span></strong>, and Hongseok Namkoong.<br>
    <i>Neural Information Processing Systems (NeurIPS) 2024</i><br>
  </div>
</div>

<h3>New computational methods and evaluations of foundation models in health and medicine</h3>

We develop and benchmark AI models in-house and in collaboration with other clinical experts and healthcare institutions. Our goal is highlight current limits and provide improvements so we can use AI models as expert reasoning agents. Our current applications are in psychiatry, cardiology, radiology, rheumatology, and neurocritical care.<br>


<div class="publication">
  <div class="text">
    <a href="https://arxiv.org/abs/2505.16941" target="_blank">
      <strong>FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records</strong>
    </a><br>
    <strong><span style="color: #003087;">Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita, Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi</span></strong><br>
    <!--i>International Conference on Machine Learning (ICML) 2023</i><br-->
  </div>
</div>